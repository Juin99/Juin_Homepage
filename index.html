<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Miao Lu</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Homepage</div>
<div class="menu-item"><a href="index.html" class="current">About&nbsp;Me</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="experiences.html">Experiences</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Miao Lu</h1>
</div>
<table class="imgtable"><tr><td>
<img src="profile.jpg" alt="alt text" width="257.71" height="300px" />&nbsp;</td>
<td align="left"><p><b>About Me</b><br /></p>
<p>Welcome to my homepage!
I am a Ph.D. student of <a href="https://msande.stanford.edu">the Department of Management Science and Engineering (MS&amp;E)</a> at <a href="https://www.stanford.edu">Stanford University</a>, majoring in Operations Research.
Prior to that, I obtained my Bachelor's degree in Probability and Statistics from the <a href="http://en.ustc.edu.cn">University of Science and Technology of China (USTC)</a>, where I won the Guo Moruo scholarship, the highest honor awarding undergraduates of USTC.</p>
<p><b>Research Interests</b><br /></p>
<p>My research interests are primarily in designing and analyzing both robust and efficient machine learning algorithms, with a special focus on the theoretical foundations. 
With such a goal, I work broadly across the theory and application of reinforcement learning and deep learning. 
Currently Iâ€™m also interested in large language models and its interaction with decision making.</p>
<p><b>Contact Information</b><br /></p>
<p>E-mail addresses: miaolu@stanford.edu, lumiao@mail.ustc.edu.cn<br /></p>
<p>Here are my [<a href="https://scholar.google.com/citations?view_op=list_works&amp;hl=zh-CN&amp;user=3jS17zQAAAAJ&amp;gmla=AJsN-F7b-8Yh03vfLpxWv7dg_zOwOUzsHmZtch3jtHn1AnlXfON8_0U4aCOR-BnSLCtfp3F0OjlUxIksNA70jCvUGbggl0Az9TQWt6_SLwYJNcOqCdQDnzA"><b>Google Scholar</b></a>] [<a href="https://github.com/MiaoLu3"><b>GitHub</b></a>] [<a href="https://www.linkedin.com/in/miao-lu-5bb9a31aa"><b>LinkedIn</b></a>] [<a href="Curriculum_Vitae.pdf"><b>CV</b></a>]</p>
</td></tr></table>
<h2>Recent News</h2>
<div class="infoblock">
<div class="blockcontent">
<p>(Oct. 2024) I am presenting our work &lsquo;&lsquo;<a href="https://arxiv.org/abs/2404.03578">Distributionally Robust Reinforcement Learning with Interactive Data Collection: Fundamental Hardness and Near-Optimal Algorithm</a>&rsquo;&rsquo; at INFORMS 2024. See you at Seattle!</p>
<p>(Sep. 2024) Our two papers (<a href="https://arxiv.org/abs/2404.03578">distributionally robust RL with interactive data collection</a> and <a href="https://arxiv.org/abs/2405.16436">provably mitigating overoptimization in RLHF</a>) are accepted to Neural Information Processing Systems (NeurIPS) 2024.</p>
</div></div>
<h2>Selected Publications  </h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2405.16436">Provably Mitigating Overoptimization in RLHF: Your SFT Loss is Implicitly an Adversarial Regularizer</a><br /> 
with Zhihan Liu, Shenao Zhang, Boyi Liu, Hongyi Guo, Yingxiang Yang, Jose Blanchet, Zhaoran Wang <br /> 
<i>Neural Information Processing Systems (NeurIPS) 2024</i> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2310.17074">Benign Oscillation of Stochastic Gradient Descent with Large Learning Rates</a><br /> 
with Beining Wu, Xiaodong Yang, Difan Zou <br /> 
<i>International Conference on Learning Representations (ICLR) 2024</i> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2305.18258">Maximize to Explore: One Objective Function Fusing Estimation, Planning, and Exploration</a><br /> 
with Zhihan Liu, Wei Xiong, Han Zhong, Hao Hu, Shenao Zhang, Sirui Zheng, Zhuoran Yang, Zhaoran Wang <br /> 
<i>Neural Information Processing Systems (NeurIPS) 2023</i> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2305.09659">Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage</a><br /> 
with Jose Blanchet, Tong Zhang, Han Zhong <br /> 
<i>Neural Information Processing Systems (NeurIPS) 2023</i> <br /></p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Copyright 2022 Miao Lu. Page generated 2024-10-04 00:57:45 PDT.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
